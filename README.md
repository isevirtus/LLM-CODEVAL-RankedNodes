# ğŸ§  LLM-CODEVAL: Validation Framework for Ranked Node Functions in Bayesian Networks

This repository contains the source code, validation scenarios, and result files for the paper:
  
> *LLM-CODEVAL: A Framework for Verifying Implementations of Mathematical Functions Using Language Models*, Softcom 2025.

---

## ğŸ“‚ Folder Structure

All content is organized under the folder `llm_codeval/`:
```
llm_codeval/
â”œâ”€â”€ bn_ranked_nodes.py # Bayesian Network implementation with 5 validated functions
â”œâ”€â”€ stratified_scenarios.csv # 48 input scenarios (2 and 3 parents) used in validation
â”œâ”€â”€ generate_tnormal_brier.py # Script to generate distributions and calculate Brier Scores
â”œâ”€â”€ model_results_48scenarios.csv # Model-calculated probability distributions (output)
â”œâ”€â”€ agena_results.txt # Reference distributions from AgenaRisk (manual extraction)
â”œâ”€â”€ comparison_results.csv # Side-by-side comparison with Brier Scores
â”œâ”€â”€ prompts_llm_validation.pdf # Prompts used for LLM validation (DeepSeek R1 & OpenAI O1)
â”œâ”€â”€ llm_codeval_article.pdf # Full paper describing the framework and results
```
---

## âœ… Purpose

LLM-CODEVAL validates **ranked-node aggregation functions** that are difficult to implement or undocumented. The process includes:

- Implementing 5 aggregation functions from literature and vendor documentation.
- Generating outputs for a set of structured scenarios.
- Validating each implementation with LLMs via prompt-based reasoning.
- Comparing the model outputs with results from AgenaRisk using Brier Score.

---

## ğŸ” Validated Functions

Implemented in `bn_ranked_nodes.py`:

| Function     | Description |
|--------------|-------------|
| `wmean`      | Weighted mean |
| `wmin`       | Weighted minimum |
| `wmax`       | Weighted maximum |
| `mixminmax`  | Convex combination of min/max |
| `mixture`    | Ranked-node combination followed by TNormal transformation |

Each function was validated via logical prompts using **OpenAI o1** and **DeepSeek R1**.

---

## ğŸš€ How to Use

### 1. Install Requirements
```bash
pip install numpy pandas scikit-learn matplotlib scipy
2. Run the Brier Score Evaluation
bash
Copiar
Editar
cd llm_codeval
python generate_tnormal_brier.py
This script:

Loads the 48 expert scenarios

Applies all functions over the inputs

Compares model outputs with AgenaRisk

Computes Brier Scores

Generates visualizations (bar charts, distributions)

ğŸ“Š Output Files
File	Description
model_results_48scenarios.csv	Distributions generated by our implementation
agena_results.txt	Distributions from AgenaRisk
comparison_results.csv	Full side-by-side comparison + Brier Score

ğŸ“ Prompt Documentation (LLM Validation)
To organize the prompts and answers:

ğŸ—‚ Suggested subfolder: llm_prompts/

llm_prompts/
â”œâ”€â”€ prompts_llm_validation.pdf        # Full prompt script
â”œâ”€â”€ prompt_example_1.png              # Screenshot of prompt in GPT/OpenAI
â”œâ”€â”€ prompt_example_2.png              # Screenshot of LLM reasoning
ğŸ’¡ Tip: Use filenames like prompt_wmean_openai.png, prompt_mixminmax_r1.png to easily track function and model.

In your README.md, you can also link to this folder:

markdown
Copiar
Editar
### ğŸ“š LLM Prompt Validation

The folder `llm_prompts/` contains:
- The prompt script used for validating all five functions.
- Screenshots of responses from both GPT-4-turbo and DeepSeek R1.
ğŸ“œ License
This project is licensed under the MIT License. See the LICENSE file for details.

